{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef73b97",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbb77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "\"\"\"Generic\"\"\"\n",
    "import warnings\n",
    "from typing import Annotated\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "\"\"\"IPython\"\"\"\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "\"\"\"LangChain\"\"\"\n",
    "import langchain_openai\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "\"\"\"LangGraph\"\"\"\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.prebuilt import InjectedState, create_react_agent, ToolNode\n",
    "from langgraph_supervisor import create_supervisor\n",
    "\n",
    "\"\"\"APIs\"\"\"\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "fred = Fred(api_key=config.Config.FRED_API_KEY)\n",
    "\n",
    "\"\"\"Data Analysis\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quantstats as qs\n",
    "\n",
    "\"\"\"Statistics\"\"\"\n",
    "import statsmodels\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaea44a",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fc1fb",
   "metadata": {},
   "source": [
    "## FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "845898a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_results = fred.search(\"FEDFUNDS\")\n",
    "# search_results = search_results[\n",
    "#     (search_results['frequency_short']=='M') | \n",
    "#     (search_results['frequency_short']=='W') |\n",
    "#     (search_results['frequency_short']=='D')\n",
    "# ]\n",
    "# search_results.sort_values('popularity', inplace=True)\n",
    "\n",
    "# result = search_results.head(1)\n",
    "# ticker = result['id'].values[0]\n",
    "# ticker_notes = result['notes'].values[0]\n",
    "\n",
    "# if ticker:\n",
    "#     ticker_df = fred.get_series(series_id=ticker)\n",
    "#     spy_df = yf.download('SPY', start=ticker_df.index[0], auto_adjust=True)['Close']\n",
    "#     spy_df = spy_df.resample('ME').last().iloc[:-2]\n",
    "#     ticker_df = ticker_df.resample('ME').last()\n",
    "#     combined_df = pd.concat([spy_df, ticker_df], axis=1)\n",
    "#     combined_df.columns = ['SP500', ticker]\n",
    "#     combined_df = combined_df.ffill().dropna()\n",
    "#     display(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ab8bc",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4d9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels\n",
    "\n",
    "# spy_df = yf.download('SPY', start='1981-01-01', auto_adjust=True)\n",
    "# spy_df.columns = spy_df.columns.get_level_values(0)\n",
    "# spy_df = spy_df['Close'].resample('W-FRI').last()\n",
    "# # spy_df = spy_df[-300:]\n",
    "\n",
    "# acf_vals = statsmodels.tsa.stattools.acf(spy_df, nlags=5, fft=True)\n",
    "\n",
    "# # Format as list of dicts for LLM use\n",
    "# acf_data = [{\"lag\": lag, \"autocorrelation\": round(acf_val, 6)} for lag, acf_val in enumerate(acf_vals) if lag != 0]\n",
    "\n",
    "# # Optionally remove lag 0 (always 1.0, not useful for transformation)\n",
    "# # acf_data = [item for item in acf_data if item[\"lag\"] > 0]\n",
    "\n",
    "# # Print nicely\n",
    "# import json\n",
    "# print(json.dumps(acf_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92c15b",
   "metadata": {},
   "source": [
    "## Load JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b21d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spy_df1 = spy_df.copy()\n",
    "# json_dict = json.loads(\n",
    "#     '[\\n    {\\\"tool\\\":\\\"sma\\\", \\\"args\\\":{\\\"window\\\":10}},\\n    {\\\"tool\\\":\\\"zscore\\\", \\\"args\\\":{\\\"window\\\":7}},\\n    {\\\"tool\\\":\\\"lag\\\", \\\"args\\\":{\\\"window\\\":3}}\\n]'\n",
    "# )\n",
    "\n",
    "# for item in json_dict:\n",
    "#     trm = item['tool']\n",
    "#     window = item['args']['window']\n",
    "\n",
    "#     if trm == 'sma':\n",
    "#         spy_df1 = spy_df1.rolling(window).mean()\n",
    "#     elif trm == 'log':\n",
    "#         if len(spy_df1[spy_df1>0])==len(spy_df1):\n",
    "#             spy_df1 = np.log(spy_df1)\n",
    "#     elif trm == 'ema':\n",
    "#         spy_df1 = spy_df1.ewm(window).mean()\n",
    "#     elif trm == 'lag':\n",
    "#         spy_df1 = spy_df1.shift(window)\n",
    "#     elif trm == 'zscore':\n",
    "#         mean = spy_df1.rolling(window).mean()\n",
    "#         std = spy_df1.rolling(window).std()\n",
    "#         zscore = (spy_df1 - mean)/std\n",
    "#         spy_df1 = zscore\n",
    "\n",
    "# spy_df1 = spy_df1.dropna()\n",
    "# spy_df1.plot()\n",
    "# plt.show()\n",
    "# spy_df.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e826a6",
   "metadata": {},
   "source": [
    "## Load Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6ba5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP500</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-01-31</th>\n",
       "      <td>24.380442</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-28</th>\n",
       "      <td>24.640554</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-03-31</th>\n",
       "      <td>25.192478</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-04-30</th>\n",
       "      <td>24.547867</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-05-31</th>\n",
       "      <td>25.209894</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-28</th>\n",
       "      <td>590.651794</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31</th>\n",
       "      <td>557.741150</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30</th>\n",
       "      <td>552.905457</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-31</th>\n",
       "      <td>587.652771</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30</th>\n",
       "      <td>587.652771</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SP500  FEDFUNDS\n",
       "1993-01-31   24.380442      3.02\n",
       "1993-02-28   24.640554      3.03\n",
       "1993-03-31   25.192478      3.07\n",
       "1993-04-30   24.547867      2.96\n",
       "1993-05-31   25.209894      3.00\n",
       "...                ...       ...\n",
       "2025-02-28  590.651794      4.33\n",
       "2025-03-31  557.741150      4.33\n",
       "2025-04-30  552.905457      4.33\n",
       "2025-05-31  587.652771      4.33\n",
       "2025-06-30  587.652771      4.33\n",
       "\n",
       "[390 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_df = pd.read_parquet('agent_files/fred_df.parquet')\n",
    "display(tmp_df)\n",
    "\n",
    "if 'signal_tfm' in tmp_df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    ax.plot(tmp_df['signal_tfm'], color='magenta')\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(tmp_df['SP500'], color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd0f70",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d565aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    symbol: str\n",
    "    fred_df_path: str\n",
    "    frequency: str\n",
    "    descriptive_stats: str\n",
    "    transform_pipeline: list\n",
    "    input: Optional[str]\n",
    "\n",
    "model = langchain_openai.AzureChatOpenAI(\n",
    "    deployment_name=config.Config.AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0,\n",
    "    openai_api_version=config.Config.OPENAI_API_VERSION,\n",
    ")\n",
    "\n",
    "llm = init_chat_model(\n",
    "    \"azure_openai:gpt-4.1-nano\",\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16524f56",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e946d1",
   "metadata": {},
   "source": [
    "### Extract Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b1877e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_symbol_from_message(state:dict) -> dict:\n",
    "    user_msg = state[\"messages\"][-1].content\n",
    "    prompt = f\"Extract the FRED series ID from this message: \\\"{user_msg}\\\". Return only the symbol, nothing else.\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    symbol = response.content.strip().upper()    \n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": [AIMessage(f\"Successfully extracted {symbol} from prompt\")],\n",
    "        \"symbol\": symbol\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9fe2c6",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(state:State) -> dict:\n",
    "    \"\"\"Download data from FRED for the given symbol.\"\"\"\n",
    "    global ticker_notes\n",
    "    ticker = None\n",
    "    symbol = state['symbol']\n",
    "\n",
    "    search_results = fred.search(symbol)\n",
    "    search_results = search_results[\n",
    "        (search_results['frequency_short']=='M') | \n",
    "        (search_results['frequency_short']=='W') |\n",
    "        (search_results['frequency_short']=='D')\n",
    "    ]\n",
    "    search_results.sort_values('popularity', inplace=True)\n",
    "\n",
    "    result = search_results.head(1)\n",
    "    ticker = result['id'].values[0]\n",
    "    ticker_notes = result['notes'].values[0]\n",
    "    file_path = 'agent_files/fred_df.parquet'\n",
    "\n",
    "    if ticker:\n",
    "        ticker_df = fred.get_series(series_id=ticker)\n",
    "        spy_df = yf.download('SPY', start=ticker_df.index[0], auto_adjust=True)['Close']\n",
    "        spy_df = spy_df.resample('ME').last().iloc[:-2]\n",
    "        ticker_df = ticker_df.resample('ME').last()\n",
    "        combined_df = pd.concat([spy_df, ticker_df], axis=1)\n",
    "        combined_df.columns = ['SP500', ticker]\n",
    "        combined_df = combined_df.ffill().dropna()\n",
    "        combined_df.to_parquet(file_path)         \n",
    "\n",
    "        return {   \n",
    "            **state,         \n",
    "            \"frequency\": \"Monthly\",\n",
    "            \"fred_df_path\": \"agent_files/fred_df.parquet\",\n",
    "            \"messages\": state[\"messages\"] + [\n",
    "                ToolMessage(\n",
    "                    tool_call_id=download_data.name, \n",
    "                    content=f\"Downloaded {symbol} and saved to parquet <{file_path}>.\"\n",
    "                )\n",
    "            ],\n",
    "            \"transform_pipeline\": [],\n",
    "            \"input\": END\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"frequency\": None,\n",
    "        \"fred_df_path\": None,\n",
    "        \"messages\": state[\"messages\"] + [f\"Symbol '{symbol}' not found.\"],\n",
    "        \"transform_pipeline\": [],\n",
    "        \"input\": END\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def download_data1(state: State) -> dict:\n",
    "    \"\"\"Download data from FRED for the given symbol.\"\"\"\n",
    "    \n",
    "    symbol = state['symbol']\n",
    "    search_results = fred.search(symbol)\n",
    "    search_results = search_results[\n",
    "        (search_results['frequency_short']=='M') | (search_results['frequency_short']=='W')]\n",
    "    search_results.sort_values('popularity', inplace=True)\n",
    "\n",
    "    result = search_results.head(1)\n",
    "    ticker = result['id'].values[0]\n",
    "    frequency = result['frequency_short'].values[0]\n",
    "    ticker_notes = result['notes'].values[0]\n",
    "\n",
    "    if ticker:\n",
    "        ticker_df = fred.get_series(series_id=ticker)\n",
    "        spy_df = yf.download('SPY', start=ticker_df.index[0], auto_adjust=True)['Close']\n",
    "        spy_df = spy_df.resample('ME').last().iloc[:-2]\n",
    "        ticker_df = ticker_df.resample('ME').last()\n",
    "        combined_df = pd.concat([spy_df, ticker_df], axis=1)\n",
    "        combined_df.columns = ['SP500', ticker]\n",
    "        combined_df = combined_df.ffill().dropna()\n",
    "        combined_df.to_parquet('agent_files/fred_df.parquet')\n",
    "\n",
    "        return {   \n",
    "            **state,         \n",
    "            \"frequency\": \"Monthly\",\n",
    "            \"fred_df_path\": \"agent_files/fred_df.parquet\",\n",
    "            \"messages\": state[\"messages\"] + [f\"Downloaded {symbol} and saved to parquet.\"],\n",
    "            \"transform_pipeline\": [],\n",
    "            \"input\": \"Run describe_data tool\"         \n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"frequency\": None,\n",
    "        \"fred_df_path\": None,\n",
    "        \"messages\": state[\"messages\"] + [f\"Symbol '{symbol}' not found.\"],\n",
    "        \"transform_pipeline\": [],\n",
    "        \"input\": \"End\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cd9e5",
   "metadata": {},
   "source": [
    "### Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2781aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_data(state: State) -> dict:\n",
    "    \"\"\"Generate descriptive stats from dataframe\"\"\"\n",
    "\n",
    "    df = pd.read_parquet(state['fred_df_path'])\n",
    "    col_name = df.columns[-1]\n",
    "    # num_obs = 300\n",
    "    # x = df[col_name].iloc[-num_obs:]\n",
    "    x = df[col_name]\n",
    "\n",
    "    # Autocorrelation (ACF)\n",
    "    acf_vals = statsmodels.tsa.stattools.acf(x, nlags=20, fft=True)\n",
    "    acf_data = [\n",
    "        {\"lag\": lag, \"autocorrelation\": round(acf_val, 6)} for lag, acf_val in enumerate(acf_vals) if lag != 0\n",
    "    ]\n",
    "\n",
    "    # Normality tests\n",
    "    try:\n",
    "        adf_pval = adfuller(x, autolag='AIC')[1]\n",
    "    except:\n",
    "        adf_pval = np.nan\n",
    "\n",
    "    desc_stats = dict(\n",
    "        num_negative=len(x[x<0]),\n",
    "        mean=np.mean(x),\n",
    "        median=np.median(x),\n",
    "        std=np.std(x, ddof=1),\n",
    "        skew=stats.skew(x),\n",
    "        kurtosis=stats.kurtosis(x, fisher=False),\n",
    "        acf=acf_data,\n",
    "        adf_pval=adf_pval,\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        f\"\"\" \n",
    "        Generate a concise summary with regards to data transformation based on the descriptive stats below\n",
    "        {json.dumps(desc_stats)}\n",
    "        If adf p-value < 0.01, dataset is stationary\n",
    "        Include observation about num_negative\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(response.content)],\n",
    "        \"descriptive_stats\": response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bb917",
   "metadata": {},
   "source": [
    "### Suggest Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2e4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def suggest_transformations(state:State):\n",
    "    \"\"\"Suggest from 1 to 3 transformations on the data based on the descriptive stats\"\"\"    \n",
    "    global ticker_notes\n",
    "\n",
    "    prompt=(f\"\"\"\n",
    "    You are selecting from 1 to 3 data transformations based on the provided descriptive statistics.\n",
    "            \n",
    "    Summary of the dataset:\n",
    "    {ticker_notes}\n",
    "\n",
    "    Summary of the descriptive stats:\n",
    "    {state['descriptive_stats']}\n",
    "    \n",
    "    NOTE:\n",
    "    - If non-stationary, suggest diff or pct_change\n",
    "    - DO NOT use pct_change if the dataset is already in percentage\n",
    "    - DO NOT use diff or percentage change if adf_pval < 0.02\n",
    "    - DO NOT suggest box_cox or log_transform if there are negative values\n",
    "    - ALWAYS use lag as the last transformation\n",
    "\n",
    "    Available tools and valid window values:\n",
    "    - diff = [1,3,5,10])\n",
    "    - pct_change = [1,3,5,10,20])        \n",
    "    - sma = [1,3,5])\n",
    "    - ema = [1,3,5])\n",
    "    - log_transform = [0]\n",
    "    - zscore = [50,100,150,200,250])\n",
    "    - minmax_scale = [20,50,100])\n",
    "    - rolling_std = [50,100,150,200,250])\n",
    "    - lag = [1,2,3,5,10,20,50])\n",
    "\n",
    "    You MUST follow these rules:\n",
    "    - Only use tools from the list above\n",
    "    - The key must be \"tool\", not \"name\"\n",
    "    - The tool name must exactly match one of the tool names listed\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    prompt += \"\"\"\n",
    "    Only return a json of this format:\n",
    "    [{\"tool\": \"log_transform\", \"args\": {\"window\": 0}},{\"tool\": \"diff\", \"args\": {\"window\": 1}}]\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    print(response.content)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": state['messages'] + [response.content],\n",
    "        \"transform_pipeline\": json.loads(response.content),\n",
    "        \"input\": \"Run implement_transformations tool\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082029d",
   "metadata": {},
   "source": [
    "### Implement Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a9e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_transformations(state:State) -> State:\n",
    "    \"\"\"Implement transformations from transform_pipeline in state dictionary\"\"\"\n",
    "\n",
    "    if state['transform_pipeline'] is not None:\n",
    "        json_dict = state['transform_pipeline']\n",
    "\n",
    "        fred_df = pd.read_parquet(state['fred_df_path'])\n",
    "        colname = 'signal_tfm'\n",
    "        fred_df[colname] = fred_df[fred_df.columns[-1]]\n",
    "\n",
    "        for item in json_dict:\n",
    "            trm = item['tool']            \n",
    "\n",
    "            if trm == 'sma':\n",
    "                fred_df[colname] = fred_df[colname].rolling(item['args']['window']).mean()\n",
    "            elif trm == 'log':\n",
    "                if len(fred_df[colname][fred_df[colname]>0])==len(fred_df[colname]):\n",
    "                    fred_df[colname] = np.log(fred_df[colname])\n",
    "            elif trm == 'ema':\n",
    "                fred_df[colname] = fred_df[colname].ewm(item['args']['window']).mean()\n",
    "            elif trm == 'lag':\n",
    "                fred_df[colname] = fred_df[colname].shift(item['args']['window'])\n",
    "            elif trm == 'log_transform':                \n",
    "                fred_df[colname] = np.log(fred_df[colname])\n",
    "            elif trm == 'zscore':\n",
    "                mean = fred_df[colname].rolling(item['args']['window']).mean()\n",
    "                std = fred_df[colname].rolling(item['args']['window']).std()\n",
    "                zscore = (fred_df[colname] - mean)/std\n",
    "                fred_df[colname] = zscore\n",
    "            elif trm == 'diff':\n",
    "                fred_df[colname] = fred_df[colname].diff(item['args']['window'])\n",
    "\n",
    "        fred_df = fred_df.ffill()\n",
    "        fred_df = fred_df.dropna()\n",
    "        fred_df.to_parquet('agent_files/fred_df.parquet')\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"input\": END\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf41304",
   "metadata": {},
   "source": [
    "## Generate Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50b1ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_performance_metrics(\n",
    "        df:pd.DataFrame, \n",
    "        colname:str, \n",
    "        num_periods:int\n",
    "):\n",
    "    avg_return = df[colname].mean()\n",
    "\n",
    "    return {\n",
    "        \"annualised_returns\": avg_return*num_periods,\n",
    "        \"annualised_volatility\":qs.stats.volatility(df[colname], periods=num_periods),\n",
    "        \"sharpe_ratio\":qs.stats.sharpe(df[colname], periods=num_periods),\n",
    "        \"sortino_ratio\":qs.stats.sortino(df[colname], periods=num_periods),\n",
    "        \"max_drawdown\":qs.stats.max_drawdown(df[colname]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d18a60",
   "metadata": {},
   "source": [
    "### Z-score reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73e61b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def zscore_reversal(state:State, buy_threshold:float, sell_threshold:float):\n",
    "    \"\"\"\n",
    "    Perform a zscore-reversal strategy where \n",
    "    1. BUY: <= Z-score threshold\n",
    "    2. SELL: >= Z-score threshold\n",
    "    \"\"\"\n",
    "\n",
    "    strat_df = pd.read_parquet(state['fred_df_path'])\n",
    "    \n",
    "    if strat_df is not None:\n",
    "        strat_df['signal'] = np.where(\n",
    "            strat_df['signal_tfm'] <= buy_threshold, 1,\n",
    "            np.where(strat_df['signal_tfm'] >= sell_threshold, -1, np.nan)\n",
    "        )\n",
    "        strat_df['signal'] = strat_df['signal'].ffill().bfill()\n",
    "        strat_df['returns'] = strat_df['SP500'].pct_change()\n",
    "        strat_df['strat_returns'] = strat_df['signal'].shift(1) * strat_df['returns']\n",
    "\n",
    "        strat_df = strat_df.dropna()        \n",
    "\n",
    "        return {\n",
    "            **state,\n",
    "            \"performance_metrics\": json.dumps(calc_performance_metrics(\n",
    "                df=strat_df, \n",
    "                colname=\"strat_returns\",\n",
    "                num_periods=12\n",
    "            ))\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        **state\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0ba98",
   "metadata": {},
   "source": [
    "### SMA Cross-over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e1a74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sma_trend(state:State, slow_sma:int, fast_sma:int):\n",
    "    \"\"\"\n",
    "    Perform a sma crossover strategy where \n",
    "    1. BUY: fast_sma > slow_sma\n",
    "    2. SELL: fast_sma < slow_sma\n",
    "    \"\"\"\n",
    "\n",
    "    strat_df = pd.read_parquet(state['fred_df_path'])\n",
    "    buy_wt = 1\n",
    "    sell_wt = -1\n",
    "    \n",
    "    if strat_df is not None:\n",
    "        strat_df['fast_sma'] = strat_df['signal_tfm'].rolling(fast_sma).mean()\n",
    "        strat_df['slow_sma'] = strat_df['signal_tfm'].rolling(slow_sma).mean()\n",
    "        strat_df['signal'] = np.where(\n",
    "            strat_df['fast_sma'] > strat_df['slow_sma'], buy_wt,\n",
    "            np.where(strat_df['fast_sma'] < strat_df['slow_sma'], sell_wt, np.nan)\n",
    "        )\n",
    "        strat_df['signal'] = strat_df['signal'].ffill().bfill()\n",
    "        strat_df['returns'] = strat_df['SP500'].pct_change()\n",
    "        strat_df['strat_returns'] = strat_df['signal'].shift(1) * strat_df['returns']\n",
    "\n",
    "        strat_df = strat_df.dropna()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12,5))\n",
    "        ax.plot(strat_df['SP500'], color='black')\n",
    "        \n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(strat_df['signal_tfm'], color='green')\n",
    "        ax2.plot(strat_df['fast_sma'], color='red')\n",
    "        ax2.plot(strat_df['slow_sma'], color='magenta')\n",
    "        for idx, row in strat_df[strat_df['signal'].diff()!=0].iterrows():\n",
    "            clr = 'blue' if row['signal'] == 1 else 'red'\n",
    "            ax2.axvline(idx, color=clr)\n",
    "        plt.show()\n",
    "\n",
    "        return {\n",
    "            **state,\n",
    "            \"performance_metrics\": calc_performance_metrics(\n",
    "                df=strat_df, \n",
    "                colname=\"strat_returns\",\n",
    "                num_periods=12\n",
    "            )\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        **state\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a5cd75",
   "metadata": {},
   "source": [
    "# ** Main **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bca4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create agents\n",
    "# ticker_notes = ''\n",
    "# agent_download = create_react_agent(\n",
    "#     model,\n",
    "#     tools=[download_data],\n",
    "#     name='download',\n",
    "#     prompt=(\n",
    "#         \"\"\"\n",
    "#         Call download_data only once. If it has already been downloaded (check fred_df_path), do not call again.\n",
    "#         \"\"\"\n",
    "#     )\n",
    "# )\n",
    "# agent_process = create_react_agent(\n",
    "#     model,\n",
    "#     tools=[describe_data],\n",
    "#     name='process',\n",
    "#     prompt=\"Read from shared state\"\n",
    "# )\n",
    "# agent_suggest = create_react_agent(\n",
    "#     model,\n",
    "#     tools=[suggest_transformations],\n",
    "#     name='suggest'\n",
    "# )\n",
    "# agent_implement = create_react_agent(\n",
    "#     model,\n",
    "#     tools=[implement_transformations],\n",
    "#     name='implement'\n",
    "# )\n",
    "# agent_gen_strategy = create_react_agent(\n",
    "#     model,\n",
    "#     tools=[zscore_reversal, sma_trend],\n",
    "#     name='generate'\n",
    "# )\n",
    "# agent_evaluate = None # Evaluate performance metrics\n",
    "\n",
    "# # Graph\n",
    "# gb_download = StateGraph(State)\n",
    "\n",
    "# # Nodes\n",
    "# gb_download.add_node(\"download_data\", agent_download)\n",
    "# gb_download.add_node(\"process_data\", agent_process)\n",
    "# gb_download.add_node(\"suggest_transformation\", agent_suggest)\n",
    "# gb_download.add_node(\"implement_transformation\", agent_implement)\n",
    "# gb_download.add_node(\"generate_strategy\", agent_gen_strategy)\n",
    "\n",
    "# # Edges\n",
    "# gb_download.add_edge(\"download_data\", \"process_data\")\n",
    "# # gb_download.add_edge(\"process_data\", \"suggest_transformation\")\n",
    "# # gb_download.add_edge(\"suggest_transformation\", \"implement_transformation\")\n",
    "# # gb_download.add_edge(\"implement_transformation\", \"generate_strategy\")\n",
    "\n",
    "# # Entry and exit point\n",
    "# gb_download.set_entry_point(\"download_data\")\n",
    "# # gb_download.set_finish_point(\"generate_strategy\")\n",
    "# graph_download = gb_download.compile()\n",
    "\n",
    "# # display(Image(graph_download.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# prompt = (\"\"\"Download the dataset `WEI` using the FRED api\"\"\")\n",
    "# result = graph_download.invoke({\n",
    "#     \"messages\": [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": prompt\n",
    "#         }\n",
    "#     ],\n",
    "# })\n",
    "\n",
    "# # Print messages\n",
    "# for m in result['messages']: \n",
    "#     m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417762f2",
   "metadata": {},
   "source": [
    "# ** Non-ReAct **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63f6b574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Download 'FEDFUNDS' dataset from Fred\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Successfully extracted FEDFUNDS from prompt\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Downloaded FEDFUNDS and saved to parquet <agent_files/fred_df.parquet>.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The dataset contains no negative values, indicating all observations are non-negative. The mean (2.59) is slightly higher than the median (2.03), with a low skewness (0.23), suggesting a roughly symmetric distribution. The standard deviation (2.21) indicates moderate variability. High autocorrelation across lags (above 0.5 up to lag 20) suggests strong temporal dependence. The Augmented Dickey-Fuller p-value (~0.05) is marginally above 0.01, indicating the data is likely non-stationary. To achieve stationarity, a data transformation such as differencing or applying a variance-stabilizing transformation (e.g., log or Box-Cox) may be necessary.\n"
     ]
    }
   ],
   "source": [
    "ticker_notes = ''\n",
    "\n",
    "g1_builder = StateGraph(State)\n",
    "\n",
    "agent_download = create_react_agent(\n",
    "    model,\n",
    "    tools=[download_data],    \n",
    "    prompt=\"\"\"\n",
    "    You are an assistant that decides which data to download based on the user's request.\n",
    "    Call the `download_data` tool with the symbol key in state.\n",
    "    Do not ask questions. Only call the tool if you have a symbol.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# agent_desc_states = create_react_agent(\n",
    "#     model,\n",
    "#     tools=[describe_data],\n",
    "#     prompt=\"\"\"\n",
    "#     You're a helper. Always call `describe_data` to summarize.\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "agent_suggest_transformations = create_react_agent(\n",
    "    model,\n",
    "    tools=[suggest_transformations],\n",
    "    prompt=\"\"\"\n",
    "    You are an assistant that has knowledge of statistics.\n",
    "    Call the `suggest_transformations` tool with the current state.\n",
    "    Suggest which transformations to make.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "agent_implement_transformations = create_react_agent(\n",
    "    model,\n",
    "    tools=[implement_transformations],\n",
    "    prompt=\"\"\"\n",
    "    You are an assistant that implements transformations.\n",
    "    Call the `implement_transformations` tool with the current state.    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "g1_builder.add_node(\"tool_extract_symbol\", extract_symbol_from_message)\n",
    "g1_builder.add_node('tool_download_data', download_data)\n",
    "g1_builder.add_node('tool_describe_data', describe_data)\n",
    "g1_builder.add_node('agent_suggest_transformations', agent_suggest_transformations)\n",
    "g1_builder.add_node('agent_implement_transformations', agent_implement_transformations)\n",
    "\n",
    "g1_builder.add_edge(\"tool_extract_symbol\", \"tool_download_data\")\n",
    "g1_builder.add_edge(\"tool_download_data\", \"tool_describe_data\")\n",
    "# g1_builder.add_edge(\"agent_describe_data\", END)\n",
    "\n",
    "g1_builder.set_entry_point(\"tool_extract_symbol\")\n",
    "g1 = g1_builder.compile()\n",
    "\n",
    "# g1_builder.add_edge(\"agent_describe_data\", \"agent_suggest_transformations\")\n",
    "# g1_builder.add_edge(\"agent_suggest_transformations\", \"agent_implement_transformations\")\n",
    "\n",
    "\n",
    "s1 = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Download 'FEDFUNDS' dataset from Fred\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = g1.invoke(s1)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()\n",
    "\n",
    "# WEI, FEDFUNDS, UNRATE, UNEMPLOYMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff4242",
   "metadata": {},
   "source": [
    "# || TEST ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g2_builder = StateGraph(State)\n",
    "# g2_builder.add_node(\"tool_download_data\", download_data)\n",
    "# g2_builder.set_entry_point(\"tool_download_data\")\n",
    "\n",
    "# g2 = g2_builder.compile()\n",
    "\n",
    "# s1 = {\n",
    "#     \"messages\": [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Download dataset from Fred\"\n",
    "#         }\n",
    "#     ],\n",
    "#     \"symbol\": \"AAA\"\n",
    "# }\n",
    "# response = await g2.ainvoke(s1)\n",
    "\n",
    "# for m in response[\"messages\"]:\n",
    "#     m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
